{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) 2 47040000\n",
      "(60000,) 1 60000\n"
     ]
    }
   ],
   "source": [
    "#written by: Gio\n",
    "\n",
    "#Import datasets\n",
    "from utils import mnist_reader\n",
    "X_train, Y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, Y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "print(X_train.shape, X_train.ndim, X_train.size)\n",
    "print(Y_train.shape, Y_train.ndim, Y_train.size)\n",
    "\n",
    "numberOfClass = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Class (MLP)\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import copy\n",
    "class myNeuralNet:\n",
    "    #Initialization of instance variables for a multilayer perceptron\n",
    "    def __init__(self, nodes, learning_rate):\n",
    "        # define sigmoid activation function\n",
    "        self.nodes = nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        for idx in range(len(self.nodes)-1):\n",
    "            self.weights.append(np.random.rand(self.nodes[idx+1], self.nodes[idx])-0.5)\n",
    "        \n",
    "        self.gd_saved_weights = []\n",
    "        for idx in range(len(self.nodes)-1):\n",
    "            self.gd_saved_weights.append(np.zeros((self.nodes[idx+1], self.nodes[idx])))\n",
    "    \n",
    "    #Instance method defining activation function used in the multilayer perceptron\n",
    "    def activation(self, e):\n",
    "        #sigmoid = 1.0/(1.0+np.exp(-e))\n",
    "        sigmoid = lambda e: scipy.special.expit(e)\n",
    "        return sigmoid(e) \n",
    "    \n",
    "    #Instance method for the propagation of the input values to the output values of the neural network\n",
    "    def predict(self, in_list):\n",
    "        in_data = np.array(in_list, ndmin=2).T\n",
    "        #print(in_data.shape)\n",
    "        current_output = in_data\n",
    "        for weight in self.weights:\n",
    "            current_output = self._forward(weight, current_output)\n",
    "        return current_output\n",
    "    \n",
    "    #Instance method that propagates values from one layer to the next\n",
    "    def _forward(self, weight, layer):\n",
    "        acti = np.dot(weight, layer)\n",
    "        return self.activation(acti)\n",
    "    \n",
    "    #Instance method that returns the gradient signal for a certain training case \n",
    "    def _gradient(self, err, output_out, input_in):\n",
    "        return np.dot(err*(output_out)*(1-output_out), input_in)\n",
    "    \n",
    "    #Instance method that optimizes the neural network using stochastic gradient descent\n",
    "    def sgd_fit(self, in_list, target_list):\n",
    "        inputs = np.array(in_list, ndmin = 2).T\n",
    "        target = np.array(target_list, ndmin = 2).T\n",
    "        \n",
    "        outputs = [inputs]\n",
    "        for weight in self.weights: \n",
    "            outputs.append(self._forward(weight, outputs[-1]))\n",
    "        \n",
    "        error_out = target-outputs[-1]\n",
    "        errors = [error_out]\n",
    "        for idx in range(len(self.weights)-1, 0, -1):\n",
    "            errors.append(np.dot(self.weights[idx].T, errors[-1]))\n",
    "        errors.reverse()\n",
    "        \n",
    "        for idx in range(len(self.weights)):\n",
    "            self.weights[idx] += self.learning_rate*self._gradient(errors[idx], outputs[idx+1], outputs[idx].T)\n",
    "    \n",
    "    #Instance method that saves the sum of all gradients within a single epoch for batch gradient descent\n",
    "    def gd_fit(self, in_list, target_list):\n",
    "        inputs = np.array(in_list, ndmin = 2).T\n",
    "        target = np.array(target_list, ndmin = 2).T\n",
    "        \n",
    "        outputs = [inputs]\n",
    "        for weight in self.weights: \n",
    "            outputs.append(self._forward(weight, outputs[-1]))\n",
    "        \n",
    "        error_out = target-outputs[-1]\n",
    "        errors = [error_out]\n",
    "        for idx in range(len(self.weights)-1, 0, -1):\n",
    "            errors.append(np.dot(self.weights[idx].T, errors[-1]))\n",
    "        errors.reverse()\n",
    "        \n",
    "        for idx in range(len(self.gd_saved_weights)):\n",
    "            self.gd_saved_weights[idx] += self._gradient(errors[idx], outputs[idx+1], outputs[idx].T)\n",
    "    \n",
    "    #Instance method that updates the weights with the saved sums of all gradients in batch gradient descent\n",
    "    def gd_update(self, numberOfSamples):\n",
    "        for idx in range(len(self.gd_saved_weights)): \n",
    "            self.weights[idx] += self.learning_rate*copy.deepcopy(self.gd_saved_weights[idx]/numberOfSamples)\n",
    "            \n",
    "        self.gd_saved_weights = []\n",
    "        for idx in range(len(self.nodes)-1):\n",
    "            self.gd_saved_weights.append(np.zeros((self.nodes[idx+1], self.nodes[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that optimizes a neural network w/ stochastic gradient descent\n",
    "def sgd_train(testNN, X_train, Y_train, epoch, counter): \n",
    "    for b in range(epoch):\n",
    "        print(\"iteration = \", b)\n",
    "        for idx in range(len(X_train)):\n",
    "            y = X_train[idx]\n",
    "            x = np.full(numberOfClass, 0.01)\n",
    "            x[int(Y_train[idx])] = 0.99\n",
    "            placeholder = np.array(y, dtype=float)\n",
    "            placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "            testNN.sgd_fit(placeholder, x)\n",
    "        if((b+1)%counter == 0):\n",
    "            training_percentage = findPercentage(X_train, Y_train)\n",
    "            test_percentage = findPercentage(X_test, Y_test)\n",
    "            fout.write(\"%d, %.2f, %.2f\\n\" %(b+1, training_percentage, test_percentage))\n",
    "    print(\"== done ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that optimizes a neural network w/ batch gradient descent\n",
    "def gd_train(testNN, X_train, Y_train, epoch, counter):\n",
    "    for b in range(epoch):\n",
    "        print(\"iteration = \", b)\n",
    "        for image, answer in zip(X_train, Y_train):\n",
    "            y = image\n",
    "            x = np.full(numberOfClass, 0.01)\n",
    "            x[answer] = 0.99\n",
    "            placeholder = np.array(y, dtype=float)\n",
    "            placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "            testNN.gd_fit(placeholder, x)\n",
    "        testNN.gd_update(len(Y_train))\n",
    "        if((b+1)%counter == 0):\n",
    "            training_percentage = findPercentage(X_train, Y_train)\n",
    "            test_percentage = findPercentage(X_test, Y_test)\n",
    "            fout.write(\"%d, %.2f, %.2f\\n\" %(b+1, training_percentage, test_percentage))\n",
    "    print(\"== done ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that optimizes the neural network w/ mini batch gradient descent\n",
    "def mini_batch_train(testNN, X_train, Y_train, epoch, batch_size, counter):\n",
    "    #MNIST is shuffled.\n",
    "    for b in range(epoch):\n",
    "        print(\"iteration = \", b)\n",
    "        batch_counter = 0\n",
    "        for image, answer in zip(X_train, Y_train):\n",
    "            batch_counter = batch_counter + 1\n",
    "            y = image\n",
    "            x = np.full(numberOfClass, 0.01)\n",
    "            x[answer] = 0.99\n",
    "            placeholder = np.array(y, dtype=float)\n",
    "            placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "            testNN.gd_fit(placeholder, x)\n",
    "            if(batch_counter == batch_size):\n",
    "                testNN.gd_update(batch_counter)\n",
    "                batch_counter = 0\n",
    "        if batch_counter != 0:\n",
    "            testNN.gd_update(batch_counter)\n",
    "        if((b+1)%counter == 0):\n",
    "            training_percentage = findPercentage(X_train, Y_train)\n",
    "            test_percentage = findPercentage(X_test, Y_test)\n",
    "            fout.write(\"%d, %.2f, %.2f\\n\" %(b+1, training_percentage, test_percentage))\n",
    "    print(\"== done ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini-batch with small changes (not important)\n",
    "def dy_mini_batch_train(testNN, X_train, Y_train, epoch, counter):\n",
    "    #MNIST is shuffled.\n",
    "    #mini_batch is dynamic in each epoch\n",
    "    batch_size = 1\n",
    "    for b in range(epoch):\n",
    "        print(\"iteration = \", b)\n",
    "        batch_counter = 0\n",
    "        for image, answer in zip(X_train, Y_train):\n",
    "            batch_counter = batch_counter + 1\n",
    "            y = image\n",
    "            x = np.full(numberOfClass, 0.01)\n",
    "            x[answer] = 0.99\n",
    "            placeholder = np.array(y, dtype=float)\n",
    "            placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "            testNN.gd_fit(placeholder, x)\n",
    "            if(batch_counter == batch_size):\n",
    "                testNN.gd_update(batch_counter)\n",
    "                batch_counter = 0\n",
    "                batch_size = batch_size*2\n",
    "        if batch_counter != 0:\n",
    "            testNN.gd_update(batch_counter)\n",
    "        if((b+1)%counter == 0):\n",
    "            training_percentage = findPercentage(X_train, Y_train)\n",
    "            test_percentage = findPercentage(X_test, Y_test)\n",
    "            fout.write(\"%d, %.2f, %.2f\\n\" %(b+1, training_percentage, test_percentage))\n",
    "    print(\"== done ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini-batch with small changes (not important)\n",
    "def dy_mini_batch_train_V2(testNN, X_train, Y_train, epoch, counter):\n",
    "    #MNIST is shuffled.\n",
    "    #mini_batch is dynamic during iteration\n",
    "    batch_size = 1\n",
    "    for b in range(epoch):\n",
    "        print(\"iteration = \", b)\n",
    "        batch_counter = 0\n",
    "        for image, answer in zip(X_train, Y_train):\n",
    "            batch_counter = batch_counter + 1\n",
    "            y = image\n",
    "            x = np.full(numberOfClass, 0.01)\n",
    "            x[answer] = 0.99\n",
    "            placeholder = np.array(y, dtype=float)\n",
    "            placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "            testNN.gd_fit(placeholder, x)\n",
    "            if(batch_counter == batch_size):\n",
    "                testNN.gd_update(batch_counter)\n",
    "                batch_counter = 0\n",
    "        batch_size = batch_size*2\n",
    "        if batch_counter != 0:\n",
    "            testNN.gd_update(batch_counter)\n",
    "        if((b+1)%counter == 0):\n",
    "            training_percentage = findPercentage(X_train, Y_train)\n",
    "            test_percentage = findPercentage(X_test, Y_test)\n",
    "            fout.write(\"%d, %.2f, %.2f\\n\" %(b+1, training_percentage, test_percentage))\n",
    "    print(\"== done ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(lower, upper, x_val):\n",
    "    sigmoid = (upper-lower)*1.0/(1.0+np.exp(-x_val))+lower\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to derive accuracy of the neural network using the test cases\n",
    "def findPercentage(X_test, Y_test):\n",
    "    denominator = 0\n",
    "    numerator = 0\n",
    "    for y, ans in zip(X_test, Y_test):\n",
    "        target = int(ans)\n",
    "        placeholder = np.array(y, dtype=float)\n",
    "        placeholder = placeholder/255.0 * 0.99 + 0.01\n",
    "        finalPrediction = testNN.predict(placeholder)\n",
    "        save = np.argmax(finalPrediction)\n",
    "\n",
    "        if(save == target):\n",
    "            numerator+=1\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"index: \", idx)\n",
    "            #print(\"result: \", save)\n",
    "            #print(\"target: \", target)\n",
    "\n",
    "    success_rate = numerator/len(X_test)\n",
    "    return success_rate\n",
    "    print(\"success_rate\", success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.01\n",
      "iteration =  0\n",
      "iteration =  1\n",
      "iteration =  2\n",
      "iteration =  3\n",
      "iteration =  4\n",
      "== done ==\n",
      "iteration =  0\n",
      "== done ==\n",
      "training percentage 0.8024666666666667 test percentage 0.7893\n"
     ]
    }
   ],
   "source": [
    "#record performance on a separate file called \"result.txt\"\n",
    "fout = open('result.txt', 'w')\n",
    "fout.write(\"epoch, rate of training, rate of test\\n\")\n",
    "learningRate = [0.01]\n",
    "for lrate in learningRate:\n",
    "    #reset random values to arbitrary\n",
    "    np.random.seed(100)\n",
    "    testNN = myNeuralNet([784, 256, 128, 100, 10], lrate) #0.3\n",
    "    print(\"learning rate\", lrate)\n",
    "    \n",
    "    #sgd_train(testNN, X_train, Y_train, epoch, counter)\n",
    "    \n",
    "    #initial training set\n",
    "    sgd_train(testNN, X_train[:10000], Y_train[:10000], 5, 1)\n",
    "    \n",
    "    #data stream \n",
    "    sgd_train(testNN, X_train[10000:], Y_train[10000:], 1, 1)\n",
    "    \n",
    "    training_percentage = findPercentage(X_train, Y_train)\n",
    "    test_percentage = findPercentage(X_test, Y_test)\n",
    "    print(\"training percentage\", training_percentage, \"test percentage\", test_percentage)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x113c084d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reference:\n",
    "#Label / Description\n",
    "#0 => T-shirt/top\n",
    "#1 => Trouser\n",
    "#2 => Pullover\n",
    "#3 => Dress\n",
    "#4 => Coat\n",
    "#5 => Sandal\n",
    "#6 => Shirt\n",
    "#7 => Sneaker\n",
    "#8 => Bag\n",
    "#9 => Ankle boot\n",
    "\n",
    "test = 10027\n",
    "print(Y_train[test])\n",
    "plt.imshow(X_train[test].reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
